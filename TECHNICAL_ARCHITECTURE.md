# Technical Architecture & Design Documentation

## Table of Contents
1. [System Overview](#system-overview)
2. [Architecture Components](#architecture-components)
3. [Agentic Design Pattern](#agentic-design-pattern)
4. [Code Flow & Execution](#code-flow--execution)
5. [Data Architecture](#data-architecture)
6. [LLM Integration](#llm-integration)
7. [Tool System](#tool-system)
8. [Logging & Observability](#logging--observability)
9. [Deployment Diagram](#deployment-diagram)

---

## System Overview

### Purpose
AI-Powered Procurement Assistant that translates natural language questions into MongoDB queries and provides intelligent responses about California state procurement data (919,734 records, 2012-2015).

### Key Characteristics
- **Agentic AI**: Uses ReAct (Reasoning + Acting) loop for autonomous decision-making
- **Multi-LLM Support**: Works with both Google Gemini and OpenAI GPT models
- **Hybrid Search**: Combines database queries with web search
- **Observable**: Comprehensive logging with token tracking and user feedback
- **Iterative**: Agent can retry queries if results appear incorrect

### Technology Stack
```
Frontend:     Streamlit (Multi-page web UI)
Backend:      Python 3.12
AI Framework: LangChain (Tool calling, message handling)
LLM Providers: Google Gemini API, OpenAI API
Database:     MongoDB (Document store)
Logging:      BigQuery / Local CSV
Search:       DuckDuckGo (via ddgs library)
```

---

## Architecture Components

### High-Level Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERFACE                           â”‚
â”‚                        (Streamlit Pages)                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   1_Config.py   â”‚ 2_Data_Setup.py â”‚   3_Chat_Assistant.py       â”‚
â”‚  - LLM Setup    â”‚  - MongoDB      â”‚   - Chat Interface          â”‚
â”‚  - Logging      â”‚  - Data Load    â”‚   - Feedback UI             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                 â”‚                   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚      Session State Manager         â”‚
         â”‚  - llm_manager                     â”‚
         â”‚  - mongo_client                    â”‚
         â”‚  - agent                           â”‚
         â”‚  - chat_logger                     â”‚
         â”‚  - messages                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚     AGENTIC AI CORE                â”‚
         â”‚  (AgenticProcurementAgent)         â”‚
         â”‚                                    â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
         â”‚  â”‚  ReAct Loop Engine       â”‚     â”‚
         â”‚  â”‚  - Reasoning             â”‚     â”‚
         â”‚  â”‚  - Tool Selection        â”‚     â”‚
         â”‚  â”‚  - Observation           â”‚     â”‚
         â”‚  â”‚  - Retry Logic           â”‚     â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
         â”‚             â”‚                      â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
         â”‚  â”‚   Tool Registry          â”‚     â”‚
         â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤     â”‚
         â”‚  â”‚ 1. get_collection_schema â”‚     â”‚
         â”‚  â”‚ 2. translate_query       â”‚     â”‚
         â”‚  â”‚ 3. execute_mongodb_query â”‚     â”‚
         â”‚  â”‚ 4. search_web            â”‚     â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚   LLM   â”‚  â”‚ MongoDB  â”‚  â”‚  Web Search â”‚
    â”‚ Manager â”‚  â”‚  Client  â”‚  â”‚   (DDGS)    â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
          â”‚           â”‚                â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Gemini   â”‚ â”‚  MongoDB    â”‚ â”‚ DuckDuck  â”‚
    â”‚    API    â”‚ â”‚   Server    â”‚ â”‚  Go API   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Breakdown

#### 1. **User Interface Layer** (`pages/`)
- **1_Config.py**: LLM configuration, logging setup
- **2_Data_Setup.py**: MongoDB connection, data loading
- **3_Chat_Assistant.py**: Main chat interface with feedback

#### 2. **Agent Layer** (`src/ai_agent_agentic.py`)
- **AgenticProcurementAgent**: Core agentic AI
- **ReAct Loop**: Iterative reasoning and acting
- **Tool Management**: Dynamic tool calling

#### 3. **LLM Layer** (`src/llm_manager.py`)
- **LLMManagerV2**: Abstraction over Gemini/OpenAI
- **Unified Interface**: Single API for both providers
- **Token Tracking**: Automatic usage monitoring

#### 4. **Database Layer** (`src/mongo_client.py`)
- **MongoDBClient**: Connection management
- **Query Execution**: Find and aggregate operations
- **Schema Inspection**: Dynamic field discovery

#### 5. **Translation Layer** (`src/query_translator_langchain.py`)
- **QueryTranslator**: Natural language to MongoDB
- **Few-Shot Learning**: Example-based translation
- **Schema-Aware**: Uses database structure

#### 6. **Logging Layer** (`src/chat_logger.py`)
- **ChatLogger**: Multi-destination logging
- **BigQuery Integration**: Structured logging
- **CSV Fallback**: Local file backup

---

## Agentic Design Pattern

### What Makes It "Agentic"?

Traditional chatbots follow a **fixed pipeline**:
```
User Query â†’ Query Translation â†’ Database Execution â†’ Response
```

Our agentic system uses a **dynamic ReAct loop**:
```
User Query â†’ [REASON â†’ ACT â†’ OBSERVE â†’ DECIDE] â†’ Response
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Loop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ReAct Loop Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ReAct Loop                            â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 1. REASON (Think)                                   â”‚   â”‚
â”‚  â”‚    LLM analyzes situation and decides next action   â”‚   â”‚
â”‚  â”‚    Output: Thought + Tool Selection                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 2. ACT (Execute)                                    â”‚   â”‚
â”‚  â”‚    Call selected tool with arguments                â”‚   â”‚
â”‚  â”‚    Options:                                         â”‚   â”‚
â”‚  â”‚    - get_collection_schema()                        â”‚   â”‚
â”‚  â”‚    - translate_query(question)                      â”‚   â”‚
â”‚  â”‚    - execute_mongodb_query(query_json)              â”‚   â”‚
â”‚  â”‚    - search_web(query)                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 3. OBSERVE (Analyze)                                â”‚   â”‚
â”‚  â”‚    Examine tool output                              â”‚   â”‚
â”‚  â”‚    Check for errors or unexpected results           â”‚   â”‚
â”‚  â”‚    Add observation to conversation history          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                     â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ 4. DECIDE (Next Step)                               â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚  â”‚    â”‚ Have enough info?                â”‚             â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â”‚         â”‚ YES                  â”‚ NO                  â”‚   â”‚
â”‚  â”‚    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚  â”‚    â”‚ Respond â”‚          â”‚ Loop Again  â”‚             â”‚   â”‚
â”‚  â”‚    â”‚  to Userâ”‚          â”‚ (Iteration++)            â”‚   â”‚
â”‚  â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â”‚                                â”‚                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                   â”‚                         â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚                          â”‚  Max Iterations â”‚                â”‚
â”‚                          â”‚   Reached (8)?  â”‚                â”‚
â”‚                          â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                â”‚
â”‚                               â”‚ YES   â”‚ NO                  â”‚
â”‚                          â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”‚                     â”‚
â”‚                          â”‚  Exit   â”‚  â”‚                     â”‚
â”‚                          â”‚ w/Error â”‚  â”‚                     â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                     â”‚
â”‚                                       â”‚                     â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚                          â”‚   Continue Loop        â”‚         â”‚
â”‚                          â”‚   (Back to REASON)     â”‚         â”‚
â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Agentic Capabilities

#### 1. **Autonomous Tool Selection**
The agent decides which tools to use based on the question:

```python
# Example decision process:
Question: "Which department spent the most?"

Iteration 1: REASON â†’ "Need schema to know field names"
            ACT â†’ get_collection_schema()
            OBSERVE â†’ "Field is 'department_name'"

Iteration 2: REASON â†’ "Now translate to aggregation query"
            ACT â†’ translate_query("Which department spent most?")
            OBSERVE â†’ "Got aggregation pipeline"

Iteration 3: REASON â†’ "Execute the query"
            ACT â†’ execute_mongodb_query(pipeline)
            OBSERVE â†’ "Results: [{'_id': 'Transportation', 'total': 99B}]"

Iteration 4: REASON â†’ "Have answer, format response"
            ACT â†’ [No tool] â†’ Final Answer
            RESPOND â†’ "Transportation spent $99 billion"
```

#### 2. **Observation & Retry**
Agent can detect issues and retry:

```python
# Example retry scenario:
Iteration 1: execute_mongodb_query({"find": {"field": "wrong_name"}})
            OBSERVE â†’ {"error": "Field 'wrong_name' doesn't exist"}

Iteration 2: REASON â†’ "Field name was wrong, check schema"
            ACT â†’ get_collection_schema()
            OBSERVE â†’ "Correct field is 'department_name'"

Iteration 3: REASON â†’ "Retry with correct field"
            ACT â†’ execute_mongodb_query({"find": {"field": "department_name"}})
            OBSERVE â†’ "Success! Got results"
```

#### 3. **Hybrid Information Retrieval**
Combines database and web search:

```python
# Example hybrid query:
Question: "Which CA dept manages healthcare and what's the US budget?"

Iteration 1: translate_query("CA healthcare department")
            execute_mongodb_query() â†’ "Dept of Health Care Services"

Iteration 2: search_web("US healthcare budget 2024")
            OBSERVE â†’ "US spends $4.5 trillion on healthcare"

Iteration 3: Combine both results in natural language response
```

### Comparison: Traditional vs Agentic

| Aspect | Traditional Pipeline | Agentic ReAct |
|--------|---------------------|---------------|
| **Flow** | Fixed sequence | Dynamic loop |
| **Error Handling** | Fail immediately | Retry with corrections |
| **Tool Use** | Predetermined | Autonomous selection |
| **Schema Knowledge** | Hardcoded | Inspects on-demand |
| **Iterations** | Single pass | Multiple passes (up to 8) |
| **Observability** | Limited | Full reasoning trace |
| **Adaptability** | None | Self-correcting |

---

## Code Flow & Execution

### Startup Sequence

```
1. User runs: streamlit run app.py
   â”‚
   â”œâ”€> app.py
   â”‚   â”œâ”€> init_session_state()
   â”‚   â”‚   â”œâ”€> Initialize: llm_config = None
   â”‚   â”‚   â”œâ”€> Initialize: mongo_client = None
   â”‚   â”‚   â”œâ”€> Initialize: agent = None
   â”‚   â”‚   â”œâ”€> Initialize: chat_logger = None
   â”‚   â”‚   â””â”€> Initialize: session_id = UUID
   â”‚   â”‚
   â”‚   â””â”€> Display welcome page with navigation
   â”‚
   â””â”€> User navigates to pages/1_Config.py
```

### Configuration Flow

```
pages/1_Config.py
   â”‚
   â”œâ”€> User selects provider: Gemini or OpenAI
   â”‚
   â”œâ”€> render_gemini_config() OR render_openai_config()
   â”‚   â”œâ”€> Detect API key from env
   â”‚   â”œâ”€> Show model selection
   â”‚   â””â”€> Return config_data dict
   â”‚
   â”œâ”€> User enables logging (optional)
   â”‚   â”œâ”€> Select: BigQuery or Local CSV
   â”‚   â”œâ”€> Configure destination
   â”‚   â””â”€> Store logging_config
   â”‚
   â”œâ”€> User clicks "Test Connection"
   â”‚   â”‚
   â”‚   â””â”€> test_llm_connection(provider, config_data)
   â”‚       â”‚
   â”‚       â”œâ”€> create_llm_manager(provider, api_key, model)
   â”‚       â”‚   â”‚
   â”‚       â”‚   â””â”€> src/llm_manager.py â†’ LLMManagerV2.__init__()
   â”‚       â”‚       â”œâ”€> _init_chat_model()
   â”‚       â”‚       â”‚   â”œâ”€> IF Gemini: _init_gemini_chat()
   â”‚       â”‚       â”‚   â”‚   â”œâ”€> Detect API key type (AQ. vs AIza)
   â”‚       â”‚       â”‚   â”‚   â””â”€> Create ChatGoogleGenerativeAI
   â”‚       â”‚       â”‚   â”‚
   â”‚       â”‚       â”‚   â””â”€> IF OpenAI: _init_openai_chat()
   â”‚       â”‚       â”‚       â”œâ”€> Check for gpt-5 model
   â”‚       â”‚       â”‚       â””â”€> Create ChatOpenAI
   â”‚       â”‚       â”‚
   â”‚       â”‚       â””â”€> test_connection()
   â”‚       â”‚           â””â”€> generate("Respond with OK")
   â”‚       â”‚
   â”‚       â””â”€> IF success:
   â”‚           â”œâ”€> st.session_state.llm_manager = llm_manager
   â”‚           â”œâ”€> st.session_state.llm_config = {...}
   â”‚           â””â”€> st.session_state.chat_logger = create_chat_logger(...)
   â”‚
   â””â”€> User clicks "Next: Data Setup"
```

### Data Setup Flow

```
pages/2_Data_Setup.py
   â”‚
   â”œâ”€> User enters MongoDB URI
   â”‚
   â”œâ”€> User clicks "Connect to MongoDB"
   â”‚   â”‚
   â”‚   â””â”€> src/mongo_client.py â†’ MongoDBClient(uri, db_name)
   â”‚       â”œâ”€> connect()
   â”‚       â””â”€> st.session_state.mongo_client = client
   â”‚
   â”œâ”€> User clicks "Load Data to MongoDB"
   â”‚   â”‚
   â”‚   â””â”€> src/data_loader.py â†’ load_procurement_data()
   â”‚       â”‚
   â”‚       â”œâ”€> Read CSV in chunks (1000 rows)
   â”‚       â”œâ”€> Parse dates, clean data
   â”‚       â”œâ”€> Insert to MongoDB in batches
   â”‚       â”œâ”€> Create indexes
   â”‚       â”‚   â”œâ”€> creation_date
   â”‚       â”‚   â”œâ”€> fiscal_year
   â”‚       â”‚   â”œâ”€> department_name
   â”‚       â”‚   â”œâ”€> supplier_name
   â”‚       â”‚   â””â”€> (creation_date, fiscal_year)
   â”‚       â”‚
   â”‚       â””â”€> Return stats (total_documents, date_range, etc.)
   â”‚
   â””â”€> st.session_state.data_loaded = True
```

### Chat Query Flow (The Agentic Loop)

```
pages/3_Chat_Assistant.py
   â”‚
   â”œâ”€> User enters: "Which department spent the most money?"
   â”‚
   â””â”€> process_query(user_query)
       â”‚
       â”œâ”€> Append to messages: {"role": "user", "content": query}
       â”‚
       â””â”€> st.session_state.agent.process_query(user_query)
           â”‚
           â””â”€> src/ai_agent_agentic.py â†’ AgenticProcurementAgent.process_query()
               â”‚
               â”œâ”€> START: Initialize counters
               â”‚   â”œâ”€> iterations = 0
               â”‚   â”œâ”€> tool_calls_made = []
               â”‚   â”œâ”€> total_input_tokens = 0
               â”‚   â””â”€> total_output_tokens = 0
               â”‚
               â”œâ”€> Build conversation messages
               â”‚   â”œâ”€> SystemMessage(system_prompt)
               â”‚   â””â”€> HumanMessage(user_question)
               â”‚
               â”œâ”€> â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚   â”‚   REACT LOOP (max 8 iterations)     â”‚
               â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚   â”‚
               â”‚   â”œâ”€> ITERATION 1
               â”‚   â”‚   â”‚
               â”‚   â”‚   â”œâ”€> THINK: llm_with_tools.invoke(messages)
               â”‚   â”‚   â”‚   â”œâ”€> LLM analyzes question
               â”‚   â”‚   â”‚   â”œâ”€> Track tokens from response_metadata
               â”‚   â”‚   â”‚   â””â”€> Returns: AIMessage with tool_calls
               â”‚   â”‚   â”‚
               â”‚   â”‚   â”œâ”€> CHECK: Does AIMessage have tool_calls?
               â”‚   â”‚   â”‚   â”œâ”€> NO â†’ Final answer ready â†’ BREAK
               â”‚   â”‚   â”‚   â””â”€> YES â†’ Continue to ACT
               â”‚   â”‚   â”‚
               â”‚   â”‚   â”œâ”€> ACT: Execute tool_calls
               â”‚   â”‚   â”‚   â”‚
               â”‚   â”‚   â”‚   â”œâ”€> Tool: "get_collection_schema"
               â”‚   â”‚   â”‚   â”‚   â””â”€> _tool_get_schema()
               â”‚   â”‚   â”‚   â”‚       â””â”€> mongo.get_collection_schema()
               â”‚   â”‚   â”‚   â”‚           â””â”€> Sample 100 docs, extract fields
               â”‚   â”‚   â”‚   â”‚
               â”‚   â”‚   â”‚   â”œâ”€> Tool: "translate_query"
               â”‚   â”‚   â”‚   â”‚   â””â”€> _tool_translate_query(user_question)
               â”‚   â”‚   â”‚   â”‚       â””â”€> translator.translate(question)
               â”‚   â”‚   â”‚   â”‚           â””â”€> LangChain query translator
               â”‚   â”‚   â”‚   â”‚               â”œâ”€> Load few-shot examples
               â”‚   â”‚   â”‚   â”‚               â”œâ”€> Build prompt with schema
               â”‚   â”‚   â”‚   â”‚               â””â”€> LLM generates MongoDB query
               â”‚   â”‚   â”‚   â”‚
               â”‚   â”‚   â”‚   â”œâ”€> Tool: "execute_mongodb_query"
               â”‚   â”‚   â”‚   â”‚   â””â”€> _tool_execute_query(query_json)
               â”‚   â”‚   â”‚   â”‚       â”œâ”€> Parse JSON to extract query_type & query
               â”‚   â”‚   â”‚   â”‚       â”œâ”€> IF query_type == "aggregate":
               â”‚   â”‚   â”‚   â”‚       â”‚   â””â”€> mongo.aggregate(pipeline)
               â”‚   â”‚   â”‚   â”‚       â””â”€> IF query_type == "find":
               â”‚   â”‚   â”‚   â”‚           â””â”€> mongo.find(filter, limit)
               â”‚   â”‚   â”‚   â”‚
               â”‚   â”‚   â”‚   â””â”€> Tool: "search_web"
               â”‚   â”‚   â”‚       â””â”€> _tool_search_web(query, max_results)
               â”‚   â”‚   â”‚           â””â”€> DuckDuckGoSearchResults(num_results)
               â”‚   â”‚   â”‚               â””â”€> Returns search snippets
               â”‚   â”‚   â”‚
               â”‚   â”‚   â”œâ”€> OBSERVE: Create ToolMessage with results
               â”‚   â”‚   â”‚   â””â”€> messages.append(ToolMessage(content=tool_output))
               â”‚   â”‚   â”‚
               â”‚   â”‚   â””â”€> TRACK: tool_calls_made.append(tool_name)
               â”‚   â”‚
               â”‚   â”œâ”€> ITERATION 2 (if needed)
               â”‚   â”‚   â””â”€> [Same THINK â†’ ACT â†’ OBSERVE cycle]
               â”‚   â”‚
               â”‚   â”œâ”€> ITERATION 3 (if needed)
               â”‚   â”‚   â””â”€> [Same cycle...]
               â”‚   â”‚
               â”‚   â””â”€> ... up to ITERATION 8
               â”‚
               â”œâ”€> EXTRACT: final_response from AIMessage.content
               â”‚
               â”œâ”€> CALCULATE: execution_time
               â”‚
               â””â”€> RETURN: {
                   "success": True,
                   "response": clean_response,
                   "iterations": 3,
                   "tools_used": ["get_collection_schema", "translate_query", "execute_mongodb_query"],
                   "execution_time": 2.45,
                   "token_count": {
                       "input_token_count": 2341,
                       "output_token_count": 156,
                       "total_token_count": 2497
                   }
               }
```

### Post-Query Flow

```
pages/3_Chat_Assistant.py (continued)
   â”‚
   â”œâ”€> Receive result from agent
   â”‚
   â”œâ”€> Add assistant message to session:
   â”‚   â””â”€> messages.append({
   â”‚       "role": "assistant",
   â”‚       "content": result["response"],
   â”‚       "query_data": result
   â”‚   })
   â”‚
   â”œâ”€> LOG INTERACTION (if enabled):
   â”‚   â”‚
   â”‚   â””â”€> log_chat_interaction(message_idx, feedback="NA")
   â”‚       â”‚
   â”‚       â””â”€> chat_logger.log_interaction(
   â”‚           session_id,
   â”‚           model,
   â”‚           user_query,
   â”‚           tools_used,
   â”‚           response,
   â”‚           user_feedback="NA",
   â”‚           token_count
   â”‚       )
   â”‚       â”‚
   â”‚       â””â”€> src/chat_logger.py â†’ ChatLogger.log_interaction()
   â”‚           â”‚
   â”‚           â”œâ”€> Prepare log_entry dict
   â”‚           â”‚
   â”‚           â”œâ”€> TRY BigQuery (if enabled):
   â”‚           â”‚   â”‚
   â”‚           â”‚   â””â”€> _log_to_bigquery(log_entry)
   â”‚           â”‚       â”œâ”€> Insert to BigQuery table
   â”‚           â”‚       â””â”€> IF SUCCESS: Done
   â”‚           â”‚
   â”‚           â””â”€> FALLBACK to CSV:
   â”‚               â””â”€> _log_to_csv(log_entry)
   â”‚                   â””â”€> Append to chat_logs.csv
   â”‚
   â”œâ”€> DISPLAY RESPONSE in chat UI:
   â”‚   â”‚
   â”‚   â””â”€> render_chat_message(role, content, query_data)
   â”‚       â”œâ”€> Show metrics: Iterations, Tools, Time, Web Status
   â”‚       â”œâ”€> Show token usage (if available)
   â”‚       â””â”€> Show feedback buttons (if logging enabled)
   â”‚
   â””â”€> User clicks feedback (ðŸ‘ or ðŸ‘Ž):
       â”‚
       â””â”€> log_chat_interaction(message_idx, feedback="upvote")
           â””â”€> Updates log with new feedback
```

### Tool Execution Details

#### Tool 1: get_collection_schema

```python
Flow:
  _tool_get_schema()
    â”‚
    â””â”€> mongo_client.get_collection_schema(collection_name)
        â”‚
        â”œâ”€> Sample 100 documents from collection
        â”‚
        â”œâ”€> Extract unique field names
        â”‚   â””â”€> For each doc:
        â”‚       â””â”€> Recursively find all keys (nested included)
        â”‚
        â”œâ”€> Determine field types
        â”‚   â””â”€> Sample values to infer: string, int, date, etc.
        â”‚
        â””â”€> Return: {
            "collection": "procurement_orders",
            "total_documents": 919734,
            "fields": {
                "purchase_order_number": "string",
                "creation_date": "date",
                "total_price": "number",
                "department_name": "string",
                ...
            }
        }
```

#### Tool 2: translate_query

```python
Flow:
  _tool_translate_query(user_question)
    â”‚
    â””â”€> translator.translate(user_question)
        â”‚
        â”œâ”€> Build context:
        â”‚   â”œâ”€> Collection schema (fields and types)
        â”‚   â””â”€> Few-shot examples (5 examples)
        â”‚
        â”œâ”€> Construct prompt:
        â”‚   """
        â”‚   You are a MongoDB query translator.
        â”‚
        â”‚   Schema: {schema}
        â”‚
        â”‚   Examples:
        â”‚   Q: "How many orders in Q1 2013?"
        â”‚   A: {"query_type": "find", "query": {...}}
        â”‚
        â”‚   Q: "Top 5 departments by spending?"
        â”‚   A: {"query_type": "aggregate", "query": [{$group...}]}
        â”‚
        â”‚   Translate: "{user_question}"
        â”‚   """
        â”‚
        â”œâ”€> LLM call: llm_manager.generate_json(prompt)
        â”‚
        â””â”€> Return: {
            "query_type": "aggregate",
            "query": [
                {"$group": {"_id": "$department_name", "total": {"$sum": "$total_price"}}},
                {"$sort": {"total": -1}},
                {"$limit": 1}
            ],
            "explanation": "Groups by department, sums spending, sorts descending"
        }
```

#### Tool 3: execute_mongodb_query

```python
Flow:
  _tool_execute_query(query_json)
    â”‚
    â”œâ”€> Parse JSON: query_data = json.loads(query_json)
    â”‚
    â”œâ”€> Extract: query_type, query
    â”‚
    â”œâ”€> IF query_type == "aggregate":
    â”‚   â”‚
    â”‚   â””â”€> mongo_client.aggregate(collection, pipeline)
    â”‚       â”œâ”€> Validate pipeline is a list
    â”‚       â”œâ”€> Execute: collection.aggregate(pipeline)
    â”‚       â”œâ”€> Convert results to list
    â”‚       â””â”€> Serialize (handle ObjectId, datetime)
    â”‚
    â””â”€> IF query_type == "find":
        â”‚
        â””â”€> mongo_client.find(collection, filter, limit=100)
            â”œâ”€> Execute: collection.find(filter).limit(100)
            â”œâ”€> Convert cursor to list
            â””â”€> Serialize results

    Return: {
        "success": true,
        "results": [
            {"_id": "Transportation", "total": 99000000000},
            ...
        ],
        "count": 1
    }
```

#### Tool 4: search_web

```python
Flow:
  _tool_search_web(query, max_results=5)
    â”‚
    â””â”€> DuckDuckGoSearchResults(num_results=max_results)
        â”‚
        â”œâ”€> DDGS().text(query, max_results)
        â”‚   â””â”€> Calls DuckDuckGo search API
        â”‚
        â”œâ”€> Format results:
        â”‚   â””â”€> [
        â”‚       {"title": "...", "snippet": "...", "url": "..."},
        â”‚       ...
        â”‚   ]
        â”‚
        â””â”€> Return: {
            "success": true,
            "query": "current inflation rate",
            "results": "snippet: ..., title: ..., link: ...",
            "count": 5
        }
```

---

## Data Architecture

### MongoDB Schema

```javascript
// Collection: procurement_orders
{
  "_id": ObjectId("..."),

  // Order Identifiers
  "purchase_order_number": "P3000123456",
  "requisition_number": "R2013-001234",
  "lpa_number": "LPA-12-0045",

  // Dates
  "creation_date": ISODate("2013-07-15T00:00:00Z"),
  "purchase_date": ISODate("2013-07-20T00:00:00Z"),
  "fiscal_year": "2013-2014",

  // Department
  "department_name": "Department of Transportation",

  // Supplier
  "supplier_code": "SUP123",
  "supplier_name": "ACME Supplies Inc.",
  "supplier_zip_code": "94105",

  // Item Details
  "item_name": "Office Chairs",
  "item_description": "Ergonomic office chairs with lumbar support",
  "quantity": 50,
  "unit_price": 299.99,
  "total_price": 14999.50,

  // Classification
  "acquisition_type": "Goods",
  "commodity_title": "Furniture and Furnishings",
  "normalized_unspsc": "56101501",

  // Location
  "location": "Sacramento, CA"
}
```

### Indexes

```javascript
// Single field indexes
db.procurement_orders.createIndex({ "creation_date": 1 })
db.procurement_orders.createIndex({ "fiscal_year": 1 })
db.procurement_orders.createIndex({ "department_name": 1 })
db.procurement_orders.createIndex({ "supplier_name": 1 })
db.procurement_orders.createIndex({ "total_price": 1 })

// Compound indexes
db.procurement_orders.createIndex({ "creation_date": 1, "fiscal_year": 1 })
db.procurement_orders.createIndex({ "supplier_name": 1, "total_price": 1 })

// Text index for search
db.procurement_orders.createIndex({ "item_name": "text", "item_description": "text" })
```

### Data Loading Pipeline

```
CSV File (919,734 rows)
    â”‚
    â”œâ”€> Read in chunks (1000 rows/batch)
    â”‚
    â”œâ”€> For each chunk:
    â”‚   â”œâ”€> Parse dates (MM/DD/YYYY â†’ ISODate)
    â”‚   â”œâ”€> Convert prices (string â†’ float)
    â”‚   â”œâ”€> Handle nulls
    â”‚   â”œâ”€> Calculate fiscal_year
    â”‚   â”‚   â””â”€> July-June fiscal year
    â”‚   â””â”€> Clean field names
    â”‚
    â”œâ”€> Insert batch to MongoDB
    â”‚   â””â”€> db.procurement_orders.insert_many(chunk)
    â”‚
    â”œâ”€> Progress bar update
    â”‚
    â””â”€> After all batches:
        â”œâ”€> Create indexes
        â””â”€> Return statistics
```

### Query Patterns

#### Aggregation Example: Top Departments by Spending

```javascript
db.procurement_orders.aggregate([
  {
    $group: {
      _id: "$department_name",
      total_spending: { $sum: "$total_price" },
      order_count: { $sum: 1 }
    }
  },
  {
    $sort: { total_spending: -1 }
  },
  {
    $limit: 10
  }
])
```

#### Find Example: Orders in Q1 2013

```javascript
db.procurement_orders.find({
  creation_date: {
    $gte: ISODate("2013-01-01"),
    $lt: ISODate("2013-04-01")
  }
}).limit(100)
```

---

## LLM Integration

### Multi-Provider Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             LLMManagerV2 (Abstraction)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Methods:                                          â”‚
â”‚  - generate(prompt) â†’ str                          â”‚
â”‚  - generate_json(prompt) â†’ dict                    â”‚
â”‚  - test_connection() â†’ dict                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Provider-Specific Initialization:                 â”‚
â”‚  - _init_gemini_chat()                            â”‚
â”‚  - _init_openai_chat()                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚               â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Gemini Branch   â”‚   â”‚ OpenAI Branchâ”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Gemini Integration

```python
# Authentication Modes:
Mode 1: API Key (Developer)
  - Key starts with "AIza"
  - Direct Google AI API
  - Free tier available

Mode 2: API Key (Vertex AI Express)
  - Key starts with "AQ."
  - Vertex AI with API key
  - No service account needed

Mode 3: Service Account
  - GOOGLE_APPLICATION_CREDENTIALS env var
  - Full Vertex AI access
  - For production deployments

# Code Flow:
if api_key.startswith("AQ."):
    # Vertex AI Express Mode
    chat_model = ChatGoogleGenerativeAI(
        model="gemini-3-pro-preview",
        google_api_key=api_key,
        vertexai=True,
        max_output_tokens=8192,
        convert_system_message_to_human=True
    )
elif api_key.startswith("AIza"):
    # Developer API
    chat_model = ChatGoogleGenerativeAI(
        model="gemini-3-pro-preview",
        google_api_key=api_key,
        max_output_tokens=8192,
        convert_system_message_to_human=True
    )
else:
    # Service Account
    credentials = service_account.Credentials.from_service_account_file(
        sa_key_path,
        scopes=["https://www.googleapis.com/auth/cloud-platform"]
    )
    chat_model = ChatGoogleGenerativeAI(
        model="gemini-3-pro-preview",
        credentials=credentials,
        project=project_id,
        vertexai=True,
        max_output_tokens=8192,
        convert_system_message_to_human=True
    )
```

### OpenAI Integration

```python
# Authentication:
- OPENAI_API_KEY environment variable
- API key starts with "sk-"

# Special Handling for GPT-5:
if model == "gpt-5":
    # GPT-5 only supports temperature=1 (default)
    chat_model = ChatOpenAI(
        model="gpt-5",
        # temperature not set (uses default 1)
        max_tokens=8192,
        api_key=api_key
    )
else:
    chat_model = ChatOpenAI(
        model=model,
        temperature=0.1,
        max_tokens=8192,
        api_key=api_key
    )
```

### Token Tracking

```python
# After each LLM call:
if hasattr(ai_msg, 'response_metadata'):
    metadata = ai_msg.response_metadata

    # OpenAI format:
    if 'token_usage' in metadata:
        usage = metadata['token_usage']
        input_tokens = usage.get('prompt_tokens', 0)
        output_tokens = usage.get('completion_tokens', 0)

    # Gemini format:
    elif 'usage_metadata' in metadata:
        usage = metadata['usage_metadata']
        input_tokens = usage.get('prompt_token_count', 0)
        output_tokens = usage.get('candidates_token_count', 0)

    # Accumulate across iterations:
    total_input_tokens += input_tokens
    total_output_tokens += output_tokens
```

---

## Tool System

### Tool Registry

```python
# LangChain @tool decorator:
@tool
def get_collection_schema() -> str:
    """
    Get the MongoDB collection schema.
    Use this when you need to know available fields.
    """
    return self._tool_get_schema()

@tool
def translate_query(user_question: str) -> str:
    """
    Translate natural language to MongoDB query.

    Args:
        user_question: Natural language question

    Returns:
        JSON with query_type, query, and explanation
    """
    return self._tool_translate_query(user_question)

@tool
def execute_mongodb_query(query_json: str) -> str:
    """
    Execute a MongoDB query.

    Args:
        query_json: JSON string with query_type and query

    Returns:
        JSON with success, results, and count
    """
    return self._tool_execute_query(query_json)

@tool
def search_web(query: str, max_results: int = 5) -> str:
    """
    Search the web using DuckDuckGo.

    Args:
        query: Search query
        max_results: Maximum results to return

    Returns:
        JSON with search results
    """
    return self._tool_search_web(query, max_results)
```

### Tool Binding

```python
# Bind tools to LLM:
tools = [get_collection_schema, translate_query, execute_mongodb_query]

if enable_web_search:
    tools.append(search_web)

llm_with_tools = llm.bind_tools(tools)
```

### Tool Invocation

```python
# LLM returns tool calls in AIMessage:
ai_msg = llm_with_tools.invoke(messages)

# Extract tool calls:
for tool_call in ai_msg.tool_calls:
    tool_name = tool_call["name"]
    tool_args = tool_call["args"]
    tool_id = tool_call["id"]

    # Execute corresponding tool:
    if tool_name == "get_collection_schema":
        output = self.tools[0].invoke({})

    elif tool_name == "translate_query":
        q = tool_args.get("user_question")
        output = self._tool_translate_query(q)

    # ... etc

    # Add result to conversation:
    messages.append(ToolMessage(
        content=output,
        tool_call_id=tool_id
    ))
```

---

## Logging & Observability

### Logging Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Chat Interaction Event              â”‚
â”‚  (user query + agent response + feedback)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    ChatLogger.log_interaction()
    â”‚                            â”‚
    â”œâ”€> Prepare log_entry dict  â”‚
    â”‚   - session_id             â”‚
    â”‚   - timestamp              â”‚
    â”‚   - model                  â”‚
    â”‚   - user_query             â”‚
    â”‚   - tools_used (JSON)      â”‚
    â”‚   - response               â”‚
    â”‚   - user_feedback          â”‚
    â”‚   - token_count (JSON)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  IF log_to_bigquery        â”‚
    â”‚  AND bq_available:         â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜
         â”‚ YES               â”‚ NO
         â”‚                   â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚  BigQuery   â”‚    â”‚  Local CSV â”‚
    â”‚  Insert     â”‚    â”‚  Append    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ IF error (network, auth):   â”‚
    â”‚ Fallback â†’ CSV              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### BigQuery Schema

```sql
CREATE TABLE `hudhud-demo.penny_demo.chat_logs` (
  session_id STRING NOT NULL,
  timestamp TIMESTAMP NOT NULL,
  model STRING,
  user_query STRING NOT NULL,
  tools_used STRING,  -- JSON array
  response STRING,
  user_feedback STRING,
  token_count STRING  -- JSON object
)
```

### CSV Format

```csv
session_id,timestamp,model,user_query,tools_used,response,user_feedback,token_count
uuid,2026-02-07T20:00:00Z,gpt-4o,"Which dept?","[""translate_query""]","Transportation",upvote,"{""input_token_count"":1234,...}"
```

### Metrics Collection

```python
# Per Query:
- iterations: Number of ReAct loop cycles
- tools_used: List of tools called
- execution_time: Total time in seconds
- token_count: {input, output, total}

# Aggregated (in BigQuery):
- Average tokens per query
- Most used tools
- User satisfaction (upvote %)
- Cost per model
- Query complexity (iterations)
```

---

## Deployment Diagram

### Local Development

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Developer's Laptop                      â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Streamlit App (localhost:8501)       â”‚      â”‚
â”‚  â”‚  - Python 3.12                        â”‚      â”‚
â”‚  â”‚  - Virtual Env (.venv/)               â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚          â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  MongoDB (localhost:27017)            â”‚      â”‚
â”‚  â”‚  - procurement_orders collection      â”‚      â”‚
â”‚  â”‚  - 919,734 documents                  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Environment Variables (.env)         â”‚      â”‚
â”‚  â”‚  - OPENAI_API_KEY                     â”‚      â”‚
â”‚  â”‚  - GOOGLE_API_KEY                     â”‚      â”‚
â”‚  â”‚  - GOOGLE_APPLICATION_CREDENTIALS     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                   â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  OpenAI API    â”‚  â”‚  Google Cloud â”‚
      â”‚  (external)    â”‚  â”‚  - Gemini API â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  - BigQuery   â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Production Deployment (Example)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Cloud Run / App Engine               â”‚
â”‚                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Streamlit Container                  â”‚      â”‚
â”‚  â”‚  - Auto-scaling (1-10 instances)      â”‚      â”‚
â”‚  â”‚  - Environment variables from Secret  â”‚      â”‚
â”‚  â”‚    Manager                            â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚          â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  MongoDB Atlas (Managed)              â”‚      â”‚
â”‚  â”‚  - M10 cluster (production)           â”‚      â”‚
â”‚  â”‚  - Auto-backup enabled                â”‚      â”‚
â”‚  â”‚  - VPC peering                        â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                   â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  OpenAI API    â”‚  â”‚  Google Cloud â”‚
      â”‚  (external)    â”‚  â”‚  - Vertex AI  â”‚
      â”‚                â”‚  â”‚  - BigQuery   â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  - IAM Auth   â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Performance Considerations

### Optimization Strategies

1. **Index Coverage**
   - All common query fields indexed
   - Compound indexes for multi-field queries
   - Query planning with `.explain()`

2. **Result Limiting**
   - Default limit: 100 documents
   - Prevents memory issues
   - Pagination for large result sets

3. **Connection Pooling**
   - MongoDB connection reused across requests
   - Streamlit session state for agent instance
   - Warm connections reduce latency

4. **Token Management**
   - Track usage per query
   - Set max_tokens limits
   - Monitor costs by model

5. **Caching** (Future)
   - Cache schema inspections
   - Cache common query translations
   - Redis for distributed cache

### Scalability

```
Current: Single instance, local MongoDB
  â”œâ”€> Handles: ~10 concurrent users
  â””â”€> Response time: 1-5 seconds

Production: Cloud-hosted, managed MongoDB
  â”œâ”€> Handles: 100+ concurrent users
  â”œâ”€> Auto-scaling: 1-10 app instances
  â”œâ”€> Response time: 2-10 seconds (with web search)
  â””â”€> Cost: ~$200/month (M10 MongoDB + LLM API costs)
```

---

## Security Considerations

1. **API Key Management**
   - Stored in environment variables
   - Never committed to git
   - Rotation policy recommended

2. **MongoDB Security**
   - Authentication enabled
   - IP whitelist
   - SSL/TLS for connections

3. **Input Validation**
   - Query sanitization
   - Tool parameter validation
   - SQL injection prevention (N/A for MongoDB, but watch for NoSQL injection)

4. **Logging Privacy**
   - User queries logged (be aware of PII)
   - BigQuery access controlled by IAM
   - Data retention policy

---

## Future Enhancements

1. **Advanced RAG**
   - Vector embeddings for semantic search
   - Pinecone/Weaviate integration

2. **Multi-Modal**
   - Chart generation from queries
   - PDF report exports

3. **Collaboration**
   - Multi-user sessions
   - Shared conversation history

4. **Advanced Analytics**
   - Query performance dashboard
   - Cost tracking by user
   - A/B testing different prompts

---

## Conclusion

This system demonstrates a production-ready agentic AI architecture with:

âœ… **Autonomous reasoning** via ReAct loop
âœ… **Multi-provider LLM support** (Gemini & OpenAI)
âœ… **Hybrid information retrieval** (Database + Web)
âœ… **Comprehensive observability** (Logging + Metrics)
âœ… **Self-correcting behavior** (Retry logic)
âœ… **Clean separation of concerns** (Modular architecture)

The agentic design pattern enables the system to handle complex, multi-step queries with minimal human intervention while maintaining full transparency into its reasoning process.
